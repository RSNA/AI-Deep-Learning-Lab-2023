{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Predictions of AI Models in Radiology (Bonus notebook)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/Sulam-Group/AI-Deep-Learning-Lab-2023/blob/bbjt-nb-fairness_interpretability/sessions/ai-fairness/bonus_explainability.ipynb)\n",
    "\n",
    "In this notebook, we will explore explainability of AI models in radiology.\n",
    "Differently from before, we will note use a model that predicts the presence of ICH at the examination-level instead of slice-level.\n",
    "\n",
    "We will use h-Shap to explain the predictions of the model and retrieve the slices in the examination that contain signs of hemorrhage.\n",
    "\n",
    "---\n",
    "\n",
    "**Before we start**\n",
    "\n",
    "1. Change Colab runtime to GPU,\n",
    "2. Add a shortcut to the shared Google Drive folder: [https://drive.google.com/drive/folders/1p90aGBS8vIX54x9ytaW8h-vk4NHXDhpR?usp=sharing](https://drive.google.com/drive/folders/1p90aGBS8vIX54x9ytaW8h-vk4NHXDhpR?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm\n",
    "\n",
    "LAB_PATH = os.path.join(\"drive/MyDrive/RSNA2023-FAIRNESS-LAB\")\n",
    "sys.path.append(LAB_PATH)\n",
    "\n",
    "!python -m pip install entmax\n",
    "from utils import (\n",
    "    get_dataset,\n",
    "    get_random_positive_examination,\n",
    "    get_series_predictor,\n",
    "    get_hshap_examination_explainer,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the Model Correctly Classify Examinations?\n",
    "\n",
    "Here, we will verify whether the model has good generalization performance on the examination-level binary classification task.\n",
    "\n",
    "---\n",
    "\n",
    "Objectives:\n",
    "\n",
    "1. Use the model to classify examinations. Use the `series=True` flag to get the model's prediction on the entire examination, for example\n",
    "```python\n",
    "output, _ = model(x, series=True)\n",
    "```\n",
    "2. Plot the ROC curve and evaluate the AUC.\n",
    "3. Pick the threshold that maximizes Youden's J statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "model = get_series_predictor(device)\n",
    "\n",
    "# Load the test dataset\n",
    "dataset = get_dataset()\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Here:\n",
    "# Predict whether an examination contains any signs of ICH\n",
    "# note: these lists will store the ground truth and predicted labels\n",
    "ground_truth, logits = [], []\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    series, target, _, _ = data\n",
    "\n",
    "    ### YOUR CODE HERE ###\n",
    "\n",
    "# Here:\n",
    "# 1. Compute the ROC curve\n",
    "# 2. Evaluate the AUC\n",
    "# 3. Find the optimal threshold that maximizes Youden's J statistic\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Here:\n",
    "# Plot everything!\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Model's Attention Weights Align with Image-level Labels?\n",
    "\n",
    "Here, we will investigate whether the attention weights of the trained model align well with the image-level binary labels.\n",
    "\n",
    "---\n",
    "\n",
    "Objectives:\n",
    "\n",
    "1. Use the `return_attention=True` flag to return the attention weights of the model, for example:\n",
    "```python\n",
    "output, aux = model(series, series=True, return_attention=True)\n",
    "attention = aux[\"attention\"]\n",
    "```\n",
    "2. Plot the ground truth image-level labels and the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random positive examination from dataset\n",
    "patient_number, (series, target, labels, _) = get_random_positive_examination()\n",
    "patient_number = patient_number.item()\n",
    "\n",
    "# Visualize 5 random positive slices within the examination\n",
    "m = 5\n",
    "_, ax = plt.subplots(figsize=(16, 9))\n",
    "positive_idx = np.where(labels == 1)[0]\n",
    "slice_idx = np.random.choice(positive_idx, m, replace=False)\n",
    "im = make_grid(dataset.denormalize(series[slice_idx]))\n",
    "ax.imshow(im.permute(1, 2, 0), cmap=\"gray\")\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"5 random positive slices\")\n",
    "plt.show()\n",
    "\n",
    "# Here:\n",
    "# Get the attention weights for the examination\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Here:\n",
    "# Plot the ground truth slice-level labels and attention weights\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining Examination-level Predictions with Shapley Values\n",
    "\n",
    "Here, we will use [h-Shap](https://www.computer.org/csdl/journal/tp/2023/04/09826424/1EVdAz76rC0) to compute each slice's contribution to the model's examination-level prediction.\n",
    "\n",
    "---\n",
    "\n",
    "Objectives:\n",
    "1. Use the `explain_examination` function to compute the Shapley values of each slice in the examination, i.e.:\n",
    "```python\n",
    "explanation = explain_examination(series)\n",
    "```\n",
    "2. Plot the ground truth image-level labels, the attention weights, and the Shapley values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_examination = get_hshap_examination_explainer(model, device)\n",
    "\n",
    "# Here:\n",
    "# Compute the Shapley values\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Here:\n",
    "# Plot everything!\n",
    "\n",
    "### YOUR CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
