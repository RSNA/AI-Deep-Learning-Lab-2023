{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Deployment using GaNDLF\n",
    "In this document, we will explore the use of GaNDLF to train and deploy a 'production' quality segmentation model using the data that we labeled in the previous step. GANDLF provides state-of-the-art segmentation models, multi-GPU training, and facilitates use of best practices for model training. Full usage instructions can be found here: https://mlcommons.github.io/GaNDLF/usage/\n",
    "\n",
    "## Prepare data CSV for GaNDLF\n",
    "First, we need to create CSV files that tells GaNDLF where our images and segmentation (label) data are stored. There are many ways to accomplish this, but a pythonic way is provided below. We will create a single CSV, which will be automatically split into training, validation, and testing sets by GaNDLF. More complete instructions for creating a data CSV can be found here: https://mlcommons.github.io/GaNDLF/usage/#constructing-the-data-csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "139ac1479f15d9a1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# get lists of image files and segmentations\n",
    "image_dir = './nifti_resampled'\n",
    "seg_dir = './nifti_resampled/labels/final'\n",
    "images = sorted(glob(os.path.join(image_dir, '*.nii.gz')))\n",
    "labels = sorted(glob(os.path.join(seg_dir, '*.nii.gz')))\n",
    "\n",
    "# make sure we are only including data with a corresponding label file\n",
    "label_ids = [os.path.basename(label).split('.')[0] for label in labels]\n",
    "images = [image for image in images if os.path.basename(image).split('.')[0] in label_ids]\n",
    "\n",
    "# prepare data for the CSV for GANDLF\n",
    "current_abs_path = os.getcwd()\n",
    "images_abs = [os.path.join(current_abs_path, rel_path) for rel_path in images]  # convert image and label paths to absolute paths\n",
    "labels_abs = [os.path.join(current_abs_path, rel_path) for rel_path in labels]  # make the header line for the CSV\n",
    "csv_header = ['SubjectID', 'Channel_0', 'Label']\n",
    "data = list(zip(label_ids, images_abs, labels_abs)) # zip file path data together\n",
    "\n",
    "# write data CSV file\n",
    "csv_file = 'data.csv'\n",
    "with open(csv_file, 'w+') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(csv_header)\n",
    "    writer.writerows(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T16:01:24.165702319Z",
     "start_time": "2023-11-16T16:01:24.123431759Z"
    }
   },
   "id": "b957e43f361b88bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identify GaNDLF config file and prepare output directories\n",
    "GaNDLF uses a YML text file to keep track of all the necessary model/training parameters. We have included a sample config file `gandlf.yml` in this code repository in the `configs` directory. This config file can be fully customized, but we will just use it out-of-the-box for this demo. Note that this config file controls the automated train/validation/testing splits. Additional config file examples can be found here: https://github.com/mlcommons/GaNDLF/tree/master/samples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b264c4cd9d1de72c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make output directories\n",
    "gandalf_out_dir = 'gandlf_out'\n",
    "if not os.path.isdir(gandalf_out_dir):\n",
    "    os.mkdir(gandalf_out_dir)\n",
    "gandalf_out_dir = 'mlcube_out'\n",
    "if not os.path.isdir(gandalf_out_dir):\n",
    "    os.mkdir(gandalf_out_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T16:01:31.206365915Z",
     "start_time": "2023-11-16T16:01:31.196684165Z"
    }
   },
   "id": "89bb68cb5ba4af52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model\n",
    "Now we are ready to train the model in GaNDLF. \n",
    "\n",
    "<span style=\"color:yellow\">WARNING: If you want to use GPU accelerated training (recommended) and you have a CUDA compatible device, then make sure you set the CUDA_VISIBLE_DEVICES environment variable. For example: `export CUDA_VISIBLE_DEVICES=0`</span>\n",
    "\n",
    "Training can be initiated with a single command in the terminal:\n",
    "\n",
    "```bash\n",
    "python gandlf_run -c configs/gandlf.yml -i data.csv -m gandlf_out -t True -d cuda\n",
    "```\n",
    "\n",
    "<span style=\"color:red\">WARNING: Model training may take hours to days to complete depending on your hardware and configuration.</span>\n",
    "\n",
    "### Explanation of arguments\n",
    "  * `-h` - Show help message and exit\n",
    "  * `-v` - Show program's version number and exit.\n",
    "  * `-c` - Model configuration - needs to be a valid YAML\n",
    "  * `-i` - Data in CSV format \n",
    "  * `-m` - Model directory where the output of the training will be stored, created if not present\n",
    "  * `-t` - True == train, False == inference\n",
    "  * `-d` - Ensure CUDA_VISIBLE_DEVICES env variable is set for GPU device, use 'cpu' for CPU workloads\n",
    " \n",
    "More detailed training instructions can be found here: https://mlcommons.github.io/GaNDLF/usage/#running-gandlf-traininginference\n",
    "\n",
    "## Package model for deployment\n",
    "Once training is done, we can package the model as an MLCube for straightforward sharing and deployment. This is done with a single command in the terminal:\n",
    "\n",
    "\n",
    "<span style=\"color:yellow\">WARNING: Deployment requires a functional Docker engine. Please refer to instructions in `dicom2deployment-initial-setup.ipynb`.</span>\n",
    "\n",
    "\n",
    "```bash\n",
    "python gandlf_deploy -c gandlf.yml -m gandlf_out --target docker --mlcube-root configs -o mlcub_out --mlcube-type model \n",
    "```\n",
    "\n",
    "### Explanation of arguments\n",
    "  * `-h` - Show help message and exit\n",
    "  * `-c` - Model configuration file\n",
    "  * `-m` - Model directory where the output of the training was saved\n",
    "  * `--target` - The target platform (--help will show all available targets)\n",
    "  * `--mlcube-root` - Directory containing mlcube.yaml (provided in the `configs` directory of this code repository)\n",
    "  * `--mlcube-type` - MLCube type (should be `model`)\n",
    "  * `-o` - Output directory where a new mlcube.yaml file to be distributed with your image will be created\n",
    "\n",
    "More detailed deployment instructions can be found here: https://mlcommons.github.io/GaNDLF/usage/#deployment\n",
    "\n",
    "## Finished!\n",
    "Congratulations! You have completed the deployment section."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2016e60028f7f76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d143f7e3aee1bd60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
