{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ef63c3",
   "metadata": {},
   "source": [
    "# Cohort Building Using the MIDRC Data Commons\n",
    "---\n",
    "This notebook briefly demonstrates how to use the MIDRC open APIs to build a cohort of MIDRC imaging studies using patient clinical data and AI-research-based annotations in the MIDRC data commons and then access and view the X-ray image files associated with those imaging studies.\n",
    "\n",
    "All cohort selection possible in the [MIDRC data explorer UI](https://data.midrc.org/explorer) can also be achieved programmatically using API requests. In this notebook, we'll select the same cohort as in the data explorer demo detailed in [these slides](https://docs.google.com/presentation/d/1xZ-shCuGVlLpHb2_CwrYvnQZnYZ3QDCcoNfcUvaxTmE/edit?usp=sharing).\n",
    "\n",
    "by Chris Meyer, PhD\n",
    "\n",
    "Manager of Data and User Services at the Center for Translational Data Science at University of Chicago\n",
    "\n",
    "Presented at the MIDRC RSNA 2023 Deep Learning Lab on November 28, 2023\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7f87c",
   "metadata": {},
   "source": [
    "## 1) Set up Python environment\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc85bb2-3ed6-4eef-a943-724eef02c41b",
   "metadata": {},
   "source": [
    "### Download an API key file containing your credentials\n",
    "---\n",
    "1) Navigate to the MIDRC data portal in your browser: https://data.midrc.org.\n",
    "2) Read and accept the DUA (if you haven't already).\n",
    "3) Navigate to the user profile page: https://data.midrc.org/identity\n",
    "4) Click on the button \"Create API Key\" and save the `credentials.json` file somewhere safe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bffd5d4",
   "metadata": {},
   "source": [
    "### Set local variables\n",
    "---\n",
    "Change the following `cred` variable path to point to your credentials file downloaded from the MIDRC data portal following the instructions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c59c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = \"/Users/christopher/Downloads/midrc-credentials.json\" # location of your MIDRC credentials, downloaded from https://data.midrc.org/identity by clicking \"Create API key\" button and saving the credentials.json locally\n",
    "api = \"https://data.midrc.org\" # The base URL of the data commons being queried. This shouldn't change for MIDRC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962e54c",
   "metadata": {},
   "source": [
    "### Install / Import Python Packages and Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a7935",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The packages below may be necessary for users to install according to the imports necessary in the subsequent cells.\n",
    "\n",
    "import sys\n",
    "#!{sys.executable} -m pip install\n",
    "#!{sys.executable} -m pip install --upgrade pandas\n",
    "#!{sys.executable} -m pip install --upgrade --ignore-installed PyYAML\n",
    "#!{sys.executable} -m pip install --upgrade pip\n",
    "#!{sys.executable} -m pip install --upgrade gen3\n",
    "#!{sys.executable} -m pip install pydicom\n",
    "#!{sys.executable} -m pip install --upgrade Pillow\n",
    "#!{sys.executable} -m pip install psmpy\n",
    "#!{sys.executable} -m pip install python-gdcm --upgrade\n",
    "#!{sys.executable} -m pip install pylibjpeg --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Python Packages and scripts\n",
    "\n",
    "import os, subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import glob\n",
    "#import gdcm\n",
    "#import pylibjpeg\n",
    "\n",
    "# import some Gen3 packages\n",
    "import gen3\n",
    "from gen3.auth import Gen3Auth\n",
    "from gen3.query import Gen3Query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7784ecc9",
   "metadata": {},
   "source": [
    "### Initiate instances of the Gen3 SDK Classes using credentials file for authentication\n",
    "---\n",
    "Again, make sure the \"cred\" directory path variable reflects the location of your credentials file (path variables set above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = Gen3Auth(api, refresh_file=cred) # authentication class\n",
    "query = Gen3Query(auth) # query class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea96784-3370-46a6-a2c7-edda947bfa8f",
   "metadata": {},
   "source": [
    "## 2) Build Cohorts by Sending Queries to the MIDRC APIs\n",
    "---\n",
    "#### General notes on sending queries:\n",
    "* There are many ways to query and access metadata for cohort building in MIDRC, but this notebook will focus on using the [Gen3](https://gen3.org) graphQL query service [\"guppy\"](https://github.com/uc-cdis/guppy/#readme). This is the backend query service that [MIDRC's data explorer GUI](https://data.midrc.org/explorer) uses. So, anything you can do in the explorer GUI, you can do with guppy queries, and more!\n",
    "* The guppy graphQL service has more functionality than is demonstrated in this simple example. You can find extensive documentation in GitHub [here](https://github.com/uc-cdis/guppy/blob/master/doc/queries.md) in case you'd like to build your own queries from scratch.\n",
    "* The Gen3 SDK (intialized as `query` above in this notebook) has Python wrapper scripts to make sending queries to the guppy graphQL API simpler. The guppy SDK package can be viewed in GitHub [here](https://github.com/uc-cdis/gen3sdk-python/blob/master/gen3/query.py).\n",
    "* Guppy queries focus on a particular type of data (cases, imaging studies, files, etc.), which corresponds to the major tabs in [MIDRC's data explorer GUI](https://data.midrc.org/explorer).\n",
    "* Queries include arguments that are akin to selecting filter values in [MIDRC's data explorer GUI](https://data.midrc.org/explorer).\n",
    "* To see more documentation about how to use and combine filters with various operator logic (like AND/OR/IN, etc.) see [this page](https://github.com/uc-cdis/guppy/blob/master/doc/queries.md#filter).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a624e-f769-46a9-b76c-2efe9713bf61",
   "metadata": {},
   "source": [
    "#### Set query parameters\n",
    "---\n",
    "* Here, we'll send a query to the `imaging_study` guppy index, which corresponds to the \"Imaging Studies\" tab of [MIDRC's data explorer GUI](https://data.midrc.org/explorer).\n",
    "* The filters defined below can be modified to return different subsets of imaging studies. Here, we'll use rather restrictive parameters so the number of studies returned is small for demonstration purposes.\n",
    "* If our query request is successful, the API response should be in JSON format, and it should contain a list of patient IDs along with any other patient data we ask for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4a36e-0647-4546-9777-6d0ad7b32750",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set some \"imaging_study\" query parameters\n",
    "\n",
    "## mRALE filter: we'll select all imaging studies annotated with an mRALE score greater than or equal to this threshold number\n",
    "mRALE_threshold = 20\n",
    "\n",
    "## days from study to positive COVID-19 test filter: we want imaging studies performed within two days after a positive test\n",
    "min_days_from_study_to_test = -2\n",
    "max_days_from_study_to_test = 0\n",
    "\n",
    "## Imaging study modality filter: we select imaging studies with a modality of either DX or CR\n",
    "study_modalities = [\"DX\", \"CR\"]\n",
    "\n",
    "## Imaging study body part filter: here we select \"chest\" as the \"LOINC system\" filter, which is the body part examined\n",
    "body_part_examined = \"Chest\"\n",
    "\n",
    "## Case filters: we will select Hispanic males 70 years of age and older\n",
    "ethnicity = \"Hispanic or Latino\"\n",
    "sex = \"Male\"\n",
    "age_threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: the \"fields\" option defines what fields we want the query to return. If set to \"None\", returns all available fields.\n",
    "\n",
    "imaging_studies = query.raw_data_download(\n",
    "                    data_type=\"imaging_study\",\n",
    "                    fields=None,\n",
    "                    filter_object={\n",
    "                        \"AND\": [\n",
    "                            {\"=\": {\"loinc_system\": body_part_examined}},\n",
    "                            {\"=\": {\"sex\": sex}},\n",
    "                            {\"=\": {\"ethnicity\": ethnicity}},\n",
    "                            {\">=\": {\"age_at_index\": age_threshold}},\n",
    "                            {\"IN\": {\"study_modality\": study_modalities}},\n",
    "                            {\"nested\": {\"path\": \"imaging_study_annotations\", \">=\": {\"midrc_mRALE_score\": mRALE_threshold}}},\n",
    "                            {\"AND\": [\n",
    "                                {\">=\": {\"days_from_study_to_pos_covid_test\": min_days_from_study_to_test}}, \n",
    "                                {\"<=\": {\"days_from_study_to_pos_covid_test\": max_days_from_study_to_test}}                                \n",
    "                            ]}\n",
    "                        ]\n",
    "                    },\n",
    "                    sort_fields=[{\"submitter_id\": \"asc\"}]\n",
    "                )\n",
    "\n",
    "if len(imaging_studies) > 0 and \"submitter_id\" in imaging_studies[0]:\n",
    "    imaging_studies_ids = [i['submitter_id'] for i in imaging_studies] ## make a list of the imaging study IDs returned\n",
    "    print(\"Query returned {} study IDs.\".format(len(imaging_studies)))\n",
    "    print(\"Data is a list with rows like this:\\n\\t {}\".format(imaging_studies[0:1]))\n",
    "else:\n",
    "    print(\"Your query returned no data! Please, check that query parameters are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33093eff-621f-452b-a0af-89af1940c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_studies_df = pd.DataFrame(imaging_studies)\n",
    "display(imaging_studies_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f29ab-ab87-4fe5-859b-d5158c0fa3d7",
   "metadata": {},
   "source": [
    "## 3) Send another query to get data file details for our cohort / case ID\n",
    "---\n",
    "The `object_id` field in each imaging study record above contains the file identifiers for all files associated with each imaging study, which could include files like third-party annotations. If we simply want to access all files associated with our list of cases, we can use those object_ids. \n",
    "\n",
    "However, in this example, we'll ask for specific types of files and get more detailed information about each of the files. This is achieved by querying the `data_file` guppy index, which corresponds to the \"Data Files\" tab of the MIDRC data explorer GUID. \n",
    "\n",
    "All MIDRC data files, including both images and annotations, are listed in the guppy index \"data_file\", which is queried in a similar manner to our query of the `imaging_study` index above. The query parameter `data_type` below determines which guppy (Elasticsearch) index we're querying.\n",
    "\n",
    "To get only `data_file` records that correspond to our imaging study cohort built previously, we'll use the list of study UIDs as a query filter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959c0ed-adde-4f34-8308-ca0f61c599cf",
   "metadata": {},
   "source": [
    "### Set 'data_file' query parameters\n",
    "---\n",
    "Here, we'll utilize the property `source_node` to filter the list of files for our cohort to only those matching the type of files we're interested in. In this example, we ask only for CR and DX (x-ray) images, which will exclude any other types of files like annotations.\n",
    "\n",
    "We're also using the property `study_uid` as a filter to restrict the `data_file` records returned down to those associated with the imaging studies in our cohort built above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f33bd1-7393-4e0a-902a-771783568280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of study UIDs to use as a filter in our data_file query\n",
    "study_uids = [i['study_uid'] for i in imaging_studies]\n",
    "study_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efabbc8-c9cb-481a-9847-50659918b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the types of data we want using \"source_node\" as a filter\n",
    "source_nodes = [\"cr_series_file\",\"dx_series_file\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2b920-15d0-4399-ab2d-4faa2748a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search for specific files associated with our cohort by adding \"study_uid\" as a filter\n",
    "# * Note: \"fields\" is set to \"None\" in this query, which by default returns all the properties available\n",
    "data_files = query.raw_data_download(\n",
    "                    data_type=\"data_file\",\n",
    "                    fields=None,\n",
    "                    filter_object={\n",
    "                        \"AND\": [\n",
    "                            {\"IN\": {\"study_uid\": study_uids}},\n",
    "                            {\"IN\": {\"source_node\": source_nodes}},\n",
    "                        ]\n",
    "                    },\n",
    "                    sort_fields=[{\"submitter_id\": \"asc\"}]\n",
    "                )\n",
    "\n",
    "if len(data_files) > 0:\n",
    "    object_ids = [i['object_id'] for i in data_files if 'object_id' in i] ## make a list of the file object_ids returned by our query\n",
    "    print(\"Query returned {} data files with {} object_ids.\".format(len(data_files),len(object_ids)))\n",
    "    print(\"Data is a list with rows like this:\\n\\t {}\".format(data_files[0:1]))\n",
    "else:\n",
    "    print(\"Your query returned no data! Please, check that query parameters are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b4805-61a3-4c22-8339-93878f201e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object_id (AKA \"data GUID\") is a globally unique file identifier that points to an actual file object in cloud storage. We'll use the object_ids along with the gen3 command-line tool to download the files these object_ids point to.\n",
    "object_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e35d9b-e8ec-4fc0-9d3c-7485446c15f3",
   "metadata": {},
   "source": [
    "## 4) Access data files using their object_id / data GUID (globally unique identifiers)\n",
    "---\n",
    "In order to download files stored in MIDRC, users need to reference the file's object_id (AKA data GUID or Globally Unique IDentifier).\n",
    "\n",
    "Once we have a list of GUIDs we want to download, we can use either the gen3-client or the gen3 SDK to download the files. You can also access individual files in your browser after logging-in and entering the GUID after the `files/` endpoint, as in this URL: https://data.midrc.org/files/GUID\n",
    "\n",
    "where GUID is the actual GUID, e.g.: https://data.midrc.org/files/dg.MD1R/b87d0db3-d95a-43c7-ace1-ab2c130e04ec\n",
    "\n",
    "For instructions on how to install and use the gen3-client, please see [the MIDRC quick-start guide](https://data.midrc.org/dashboard/Public/documentation/Gen3_MIDRC_GetStarted.pdf), which can be found linked here and in the MIDRC data portal header as \"Get Started\".\n",
    "\n",
    "Below we use the gen3 SDK command `gen3 drs-pull object` which is [documented in detail here](https://github.com/uc-cdis/gen3sdk-python/blob/master/docs/howto/drsDownloading.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449f221-1d8d-4501-86af-111111fc7bf3",
   "metadata": {},
   "source": [
    "### Use the Gen3 SDK command `gen3 drs-pull object` to download an individual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3462219-202b-4d59-9a3d-14cbdecab77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a new directory for downloaded files\n",
    "os.system(\"rm -r downloads\")\n",
    "os.system(\"mkdir -p downloads\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b156930-805f-4562-aea7-62798b13e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can use a simple loop to download all files and keep track of successes and failures\n",
    "\n",
    "success,failure,other=[],[],[]\n",
    "count,total = 0,len(object_ids)\n",
    "for object_id in object_ids:\n",
    "    count+=1\n",
    "    cmd = \"gen3 --auth {} --endpoint data.midrc.org drs-pull object {} --output-dir downloads\".format(cred,object_id)\n",
    "    stout = subprocess.run(cmd, shell=True, capture_output=True)\n",
    "    print(\"Progress ({}/{}): {}\".format(count,total,stout.stdout))\n",
    "    if \"failed\" in str(stout.stdout):\n",
    "        failure.append(object_id)\n",
    "    elif \"successfully\" in str(stout.stdout):\n",
    "        success.append(object_id)\n",
    "    else:\n",
    "        other.append(object_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ebe63-380a-4606-8285-5736ec87ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all downloaded .dcm files\n",
    "image_files = glob.glob(pathname='**/*.dcm',recursive=True,)\n",
    "image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c1364-aba9-461f-a0f9-e7730875a339",
   "metadata": {},
   "source": [
    "### View the DICOM Images\n",
    "---\n",
    "Here we'll use the [Python package `pydicom`](https://pydicom.github.io/pydicom/stable/) to view the downloaded DICOM images. \n",
    "\n",
    "Note that some of the files may contain compressed pixel data that require other packages to view; so, for this demo we'll simply skip over those using the following loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ce308-3618-47b2-bae1-ad4681feab02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image_file in image_files:\n",
    "    print(image_file)\n",
    "    ds = pydicom.dcmread(image_file)\n",
    "    try:\n",
    "        new_image = ds.pixel_array.astype(float)\n",
    "        scaled_image = (np.maximum(new_image, 0) / new_image.max()) * 255.0\n",
    "        scaled_image = np.uint8(scaled_image)\n",
    "        final_image = Image.fromarray(scaled_image)\n",
    "        print(type(final_image))\n",
    "        display(final_image)\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't view {}: {}.\".format(image_file,e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb7027-7fb3-47cb-8b4b-2d084287fc20",
   "metadata": {},
   "source": [
    "#### View the DICOM Headers\n",
    "---\n",
    "DICOM files have metadata elements embedded in the images. These can also be read and viewed using the `pydicom` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbb4c1-9ab6-4260-904e-977836b57a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pydicom.dcmread(image_files[0],force=True)\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec9bce-7f8f-48ee-abe1-6bc380d923c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access individual elements\n",
    "display(ds.file_meta)\n",
    "display(ds.ImageType)\n",
    "display(ds[0x0008, 0x0016])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecceb434-83f2-45f1-b1f0-7e1c58fafde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the dicom metadata for all files as a DataFrame\n",
    "dfs = []\n",
    "for image_file in image_files:\n",
    "    ds = pydicom.dcmread(image_file)\n",
    "    df = pd.DataFrame(ds.values())\n",
    "    df[0] = df[0].apply(lambda x: pydicom.dataelem.DataElement_from_raw(x) if isinstance(x, pydicom.dataelem.RawDataElement) else x)\n",
    "    df['name'] = df[0].apply(lambda x: x.name)\n",
    "    df['value'] = df[0].apply(lambda x: x.value)\n",
    "    df = df[['name', 'value']]\n",
    "    df = df.set_index('name').T.reset_index(drop=True)\n",
    "    df['filename'] = image_file\n",
    "    df.drop(columns=['Pixel Data'],inplace=True) # drop the pixel data as it's too large and nonsensical to store in a DataFrame\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55cd95-570b-42d0-80cd-fb47693c49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a master dataframe for all images using only headers in all dataframes\n",
    "headers = list(set.intersection(*map(set,dfs)))\n",
    "df = pd.concat([df[headers] for df in dfs])\n",
    "df.set_index('filename',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f11af-4b8c-4744-bc88-6cd2ced7e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b991196-5298-43b6-987a-90de9bf308e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the file metadata as a TSV file\n",
    "filename = \"MIDRC_DICOM_metadata.tsv\"\n",
    "df.to_csv(filename, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544761e9",
   "metadata": {},
   "source": [
    "## The End\n",
    "---\n",
    "If you have any questions related to this notebook don't hesitate to reach out to the MIDRC Helpdesk at midrc-support@datacommons.io or the author directly at cgmeyer@uchicago.edu\n",
    "\n",
    "Happy data wrangling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6691638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
